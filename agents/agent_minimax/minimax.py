import numpy as np
from agents.common import *



def generate_move_minimax(
        board: np.ndarray, player: BoardPiece, saved_state: Optional[SavedState]
) -> Tuple[PlayerAction, Optional[SavedState]]:
    """
    generate move function employing minimax algorithm with/without alpha-beta pruning
     Parameters
    -----------
    board: np.ndarray
        board reflecting current game state
    player: BoardPiece
        player for which the minimax algorithm is supposed to calculate an action

    Return
    -----------
    action
        action for player, generated by minimax
    """

    depth = 3
    """change comment to use/not use alpha-beta pruning"""
    action, _ = minimax(board, depth, player, True)
    # action, _ = minimax_alpha_beta_pruning(board, MINIMAX_DEPTH, player, True, -np.inf, +np.inf)

    return action, saved_state


def minimax_alpha_beta_pruning(
        board: np.ndarray, depth, player: BoardPiece, maximizing: bool, alpha, beta
):
    """
    Minimax algorithm with alpha-beta pruning
    Parameters
    -----------
    board: np.ndarray
        board reflecting current game state
    depth: int
        depth explored by the minimax algorithm
    player: BoardPiece
        player for which the minimax algorithm is supposed to calculate an action
    maximizing : Bool
        if True, result is maximized for the given player
    alpha
        alpha-value for pruning, if MAXIMIZING = True, should be initialized to -np.inf
    beta
        beta-value for pruning, if MAXIMIZING = True, should be initialized to +np.inf

    Return
    -----------
    Tuple [action (best column), heuristic_value]
    """

    opponent = PLAYER2 if player == PLAYER1 else PLAYER1

    """Edge Case: (terminal node) AI or Player is winning with the next piece or the board is full (draw)"""
    terminal_state = check_end_state(board, player)

    if terminal_state == GameState.IS_WIN and maximizing:  # Maximizing Player is Winning
        # print("winning")
        return -1, np.inf
    elif terminal_state == GameState.IS_WIN and maximizing == False:  # Maximizing Player looses because Minimizing player wins
        # print("loosing")
        return -1, -np.inf
    elif terminal_state == GameState.IS_DRAW:  # Game over because draw
        return -1, None

    if depth == 0:  # case where depth = 0
        value_for_depth0 = evaluate_board(board, player)
        return -1, value_for_depth0

    valid_columns = get_valid_columns(board)
    best_column = np.random.choice(valid_columns, 1)

    """ recursive minimizing/maximizing case"""
    if maximizing:  # maximizing for player
        value = -np.inf
        for column in valid_columns:
            c_board = apply_player_action(board, column, player, True)  ### player
            _, new_score = minimax_alpha_beta_pruning(c_board, depth - 1, opponent, False, alpha,
                                                      beta)  ### maximizingTrue is False for next iter, because  will be oppnent
            if new_score > value:
                value = new_score
                best_column = column
            alpha = max(alpha, new_score)
            if alpha >= beta:
                break  ### beta cut-off

        return best_column, value

    else:  # minimizing for opponent
        value = np.inf
        for column in valid_columns:
            c_board = apply_player_action(board, column, opponent, True)  ### opponent is minimizing player
            _, new_score = minimax_alpha_beta_pruning(c_board, depth - 1, player, True, alpha,
                                                      beta)  ### maximizingTrue is True for next iter, because will be player
            if new_score < value:
                value = new_score
                best_column = column
            beta = min(beta, new_score)
            if alpha >= beta:
                break  ### alpha cut off

        return best_column, value


def minimax(
        board: np.ndarray, depth: int, player: BoardPiece, MAXIMIZING: bool
):
    """
    Minimax algorithm
    Parameters
    -----------
    board: np.ndarray
        board reflecting current game state
    depth: int
        depth explored by the minimax algorithm
    player: BoardPiece
        player for which the minimax algorithm is supposed to calculate an action
    MAXIMIZING : Bool
        if True, result is maximized for the given player

    Return
    -----------
    Tuple [action (best column), heuristic_value]
    """

    opponent = PLAYER2 if player == PLAYER1 else PLAYER1

    """Edge Case: (terminal node) AI or Player is winning with the next piece or the board is full (draw)"""
    terminal_state = check_end_state(board, player)

    if terminal_state == GameState.IS_WIN and MAXIMIZING == True:  # Maximizing Player is Winning
        # print("winning")
        return -1, np.inf
    elif terminal_state == GameState.IS_WIN and MAXIMIZING == False:  # Maximizing Player looses because Minimizing player wins
        # print("loosing")
        return -1, -np.inf
    elif terminal_state == GameState.IS_DRAW:  # Game over because draw
        return -1, None

    if depth == 0:  # case where depth = 0
        value_for_depth0 = evaluate_board(board, player)
        return -1, value_for_depth0

    valid_columns = get_valid_columns(board)
    best_column = np.random.choice(valid_columns, 1)

    """ recursive minimizing/maximizing case"""
    if MAXIMIZING:  # maximizing for player
        # print("maximizing works")
        value = -np.inf
        for column in valid_columns:
            c_board = apply_player_action(board, column, player, True)  ### player
            _, new_score = minimax(c_board, depth - 1, opponent,
                                   False)  ### maximizingTrue is False for next iter, because  will be oppnent
            if new_score > value:
                value = new_score
                best_column = column
            # print("after column", column, "best column is", best_column)

        return best_column, value

    else:  # minimizing for opponent
        # print("minimizing works")
        value = np.inf
        for column in valid_columns:
            c_board = apply_player_action(board, column, opponent, True)  ### opponent is minimizing player
            _, new_score = minimax(c_board, depth - 1, player,
                                   True)  ### maximizingTrue is True for next iter, because will be player
            if new_score < value:
                value = new_score
                best_column = column
            # print("after column", column, "best column is", best_column)

        return best_column, value


def get_valid_columns(board: np.ndarray) -> np.ndarray:
    """
    Function returning list of all columns with possible valid moves for current board
     Parameters
    -----------
    board: np.ndarray
        board reflecting current game state

    Return
    -----------
    valid_columns_array:
        array containing indices of all valid columns """

    valid_columns_array = []  # initialize empty list

    for m, col in enumerate(board.T):
        for n, row in enumerate(col):
            if board.T[m, n] == 0:
                valid_columns_array.append(m)
                break
    return valid_columns_array


def evaluate_window(window: np.ndarray, player: BoardPiece) -> int:
    """
    evaluate a window (fraction of the board) passed into the function by func: evaluate_board
     in terms of player pieces, opponent  pieces and empty slots

     Parameters
    -----------
    window:
        array of shape (4,)
    player: BoardPiece
        Player for whom the window (i.e. the board) is evaluated

    Return
    -----------
    window_score: int
        score for the respective window
    """
    window_score = 0
    opponent = PLAYER2 if player == PLAYER1 else PLAYER1

    """Raise score if Player has 1 or more pieces in a window"""
    if sum(window == player) == 3 and sum(window == NO_PLAYER) == 1:
        window_score += 70
    if sum(window == player) == 2 and sum(window == NO_PLAYER) == 2:
        window_score += 5
    if sum(window == player) == 1 and sum(window == NO_PLAYER) == 3:
        window_score += 2

    """penalty if opponent hast 1 or more pieces in a window with empty space next to it"""
    if sum(window == opponent) == 3 and sum(window == NO_PLAYER) == 1:
        window_score -= 70
    if sum(window == opponent) == 2 and sum(window == NO_PLAYER) == 2:
        window_score -= 5
    if sum(window == opponent) == 1 and sum(window == NO_PLAYER) == 3:
        window_score -= 2

    return window_score


def evaluate_board(
        board: np.ndarray, player: BoardPiece
) -> int:
    """
    return a score reflecting the state of the board for the given player

     Parameters
    -----------
    board: np.ndarray
        board reflecting current game state
    player: BoardPiece
        Player for whom the the board) is evaluated

    Return
    -----------
    board_score: int
        score for the respective window
    """

    WINDOW_LENGTH = 4  # Window length to be evaluated (=4 for connect 4)
    slide = WINDOW_LENGTH - 1  # reducing parameter based on window length when iterating over the board
    board_score = 0  # initialize board score to 0
    n_rows, m_columns = board.shape  # initialize board shape

    """ evaluate horizontally """
    for r, row in enumerate(board):
        for c in range(m_columns - slide):
            window = row[c:c + WINDOW_LENGTH]
            board_score += evaluate_window(window, player)

    """ evaluate horizontally """
    tboard = np.transpose(board)
    for r, trow in enumerate(tboard):
        for c in range(n_rows - slide):
            window = trow[c:c + WINDOW_LENGTH]
            board_score += evaluate_window(window, player)

    """  positive slope diagonal evaluation """
    for r in range(n_rows - slide):
        for c in range(m_columns - slide):
            window = np.asarray([board[r + step, c + step] for step in range(WINDOW_LENGTH)])
            board_score += evaluate_window(window, player)

    """ negative slope diagonal evaluation """
    for r in range(n_rows - slide):
        for c in range(m_columns - slide):
            window = np.asarray([board[r + slide - step, c + step] for step in range(WINDOW_LENGTH)])
            board_score += evaluate_window(window, player)

    return board_score


def pick_smart_move(
        board: np.ndarray, player: BoardPiece, saved_state: Optional[SavedState]
) -> Tuple[PlayerAction, Optional[SavedState]]:
    """
    Test function for playing against an agent which uses the evaluate board function
    Parameters
    -----------
    board: np.ndarray
        board reflecting current game state
    player: BoardPiece
        Player for whom next move is supposed to be generated

    Return
    -----------
    best_column: action
        column to be played next
    """

    """ get all valid columns, initialize best_column at random and best_column_score = 0"""
    best_column_score = 0
    valid_columns = get_valid_columns(board)
    best_column = np.random.choice(valid_columns, 1)

    """ generate a hypothetical board for all possible moves and evaluate it, choose move with highest score """
    for column in valid_columns:
        c_board = apply_player_action(board, column, player, True)
        score = evaluate_board(c_board, player)
        if score > best_column_score:
            best_column_score = score
            best_column = column

    return best_column, saved_state
